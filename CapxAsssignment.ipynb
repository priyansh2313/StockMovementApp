{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-ziTblis1Ut"
      },
      "outputs": [],
      "source": [
        "pip install praw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1XxY-fa5JpI"
      },
      "source": [
        "***Data Scraping***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTelCABJ5Fzk"
      },
      "outputs": [],
      "source": [
        "import praw\n",
        "\n",
        "reddit = praw.Reddit(client_id='dso-2wKoiaavUz1AoA3BCQ',\n",
        "                     client_secret='NkN503DNQF3R5aNrW9ebO_WC1TqEAA',\n",
        "                     user_agent='StockDataScraper v1.0')\n",
        "\n",
        "\n",
        "subreddit = reddit.subreddit('stocks')\n",
        "\n",
        "\n",
        "top_posts = subreddit.top(limit=10)\n",
        "\n",
        "\n",
        "for post in top_posts:\n",
        "    print(f\"Title: {post.title}\")\n",
        "    print(f\"Text: {post.selftext}\")\n",
        "    print(f\"Score: {post.score}\")\n",
        "    print(f\"URL: {post.url}\")\n",
        "    print('-' * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7wi4uiiFIJy"
      },
      "outputs": [],
      "source": [
        "subreddits = ['stocks', 'investing', 'StockMarket', 'wallstreetbets', 'finance']\n",
        "\n",
        "all_posts = []\n",
        "\n",
        "for subreddit in subreddits:\n",
        "    print(f\"Fetching posts from r/{subreddit}...\")\n",
        "    posts = reddit.subreddit(subreddit).search('stock', limit=400)\n",
        "    for post in posts:\n",
        "        all_posts.append({\n",
        "            'Title': post.title,\n",
        "            'Author': post.author.name if post.author else 'N/A',\n",
        "            'Upvotes': post.score,\n",
        "            'Comments': post.num_comments,\n",
        "            'Created': post.created_utc,\n",
        "            'URL': post.url\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE CSV"
      ],
      "metadata": {
        "id": "U5rKHMMoydqb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhdbj2RtFOD8"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame(all_posts)\n",
        "\n",
        "\n",
        "df.to_csv('reddit_combined_posts.csv', index=False)\n",
        "print(f\"Collected {len(df)} posts across all subreddits.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ6dGMx0Ftma"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data=pd.read_csv('/content/reddit_combined_posts.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "G1_DmjKqGKw4",
        "outputId": "acd29ccf-ebce-496c-f88a-577720373511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Title       0\n",
              "Author      0\n",
              "Upvotes     0\n",
              "Comments    0\n",
              "Created     0\n",
              "URL         0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Author</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Upvotes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Comments</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Created</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>URL</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpIJNCkB7smE"
      },
      "source": [
        "DATA PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1823SKQ4sXcQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('reddit_combined_posts.csv')\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(df.info())\n",
        "\n",
        "print(df.isnull().sum())\n",
        "\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "df = df.dropna(subset=['Title'])\n",
        "\n",
        "print(f\"Dataset after cleaning has {len(df)} entries.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMigSD84KwPT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "df = pd.read_csv('reddit_combined_posts.csv')\n",
        "\n",
        "df = df.dropna(subset=['Title'])\n",
        "\n",
        "def preprocess_text_spacy(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
        "\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df['Cleaned_Title'] = df['Title'].apply(preprocess_text_spacy)\n",
        "\n",
        "print(df[['Title', 'Cleaned_Title']].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING A TARGET COLUMN"
      ],
      "metadata": {
        "id": "FpreQlEVR24e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_upvotes(upvotes):\n",
        "    if upvotes > 1000:\n",
        "        return 1  # Positive\n",
        "    elif upvotes > 500:\n",
        "        return 0  # Neutral\n",
        "    else:\n",
        "        return -1  # Negative\n",
        "\n",
        "df['Label'] = df['Upvotes'].apply(classify_upvotes)\n",
        "\n",
        "print(df[['Title', 'Upvotes', 'Label']].head())\n"
      ],
      "metadata": {
        "id": "dKVy5eVZR5uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "TTm4i1SnRUW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HANDLING NULL VALUES FOR THE TARGET VALUE"
      ],
      "metadata": {
        "id": "K7vc5NI1RDGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Missing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "target_column = 'Label'\n",
        "\n",
        "if target_column in df.columns:\n",
        "    df = df.dropna(subset=[target_column])\n",
        "else:\n",
        "    raise ValueError(f\"Target column '{target_column}' not found in the dataset.\")\n",
        "\n",
        "print(f\"Dataset shape after dropping null values: {df.shape}\")\n",
        "\n",
        "selected_features = ['Cleaned_Title']\n",
        "selected_target = target_column\n",
        "\n",
        "df_model = df[selected_features + [selected_target]]\n",
        "\n",
        "print(\"Data prepared for modeling:\")\n",
        "print(df_model.head())\n"
      ],
      "metadata": {
        "id": "lhRSyZVmRJMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURE SELECTION"
      ],
      "metadata": {
        "id": "yAi0hREJSmkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "KEEPING ONLY THE NEEDED COLUMNS"
      ],
      "metadata": {
        "id": "fb505JJrSrgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_columns = ['Cleaned_Title', 'Upvotes', 'Comments', 'Label']\n",
        "df = df[selected_columns]\n",
        "\n",
        "print(\"Dataset preview:\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "1KnJ7fTBTz99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEXT PREPROCESSING AND VECTORIZATION"
      ],
      "metadata": {
        "id": "qcHx4IhGT-A7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_text = vectorizer.fit_transform(df['Cleaned_Title'])\n",
        "\n",
        "print(\"TF-IDF feature shape:\", X_text.shape)\n"
      ],
      "metadata": {
        "id": "fPRYRVgsUA31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMBINING TEXT WITH NUMERICAL VALUES"
      ],
      "metadata": {
        "id": "qx6xWOKdUNQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "\n",
        "numerical_features = df[['Upvotes', 'Comments']].values\n",
        "X_combined = hstack([X_text, numerical_features])\n",
        "\n",
        "\n",
        "y = df['Label']\n",
        "\n",
        "print(\"Combined feature shape:\", X_combined.shape)\n"
      ],
      "metadata": {
        "id": "wvb5barKULeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN-TEST SPLIT"
      ],
      "metadata": {
        "id": "sqSD6To8Sw7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "id": "-l4Hpd_4T1eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING THE MODEL AND CONFUSION MATRIX"
      ],
      "metadata": {
        "id": "sOTri-w7UfR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "3xVZzyPsUZWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE MODEL"
      ],
      "metadata": {
        "id": "Hh3XKIiqtjjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(model, 'random_forest_model.pkl')\n"
      ],
      "metadata": {
        "id": "Jn3GSa3ZxAOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "id": "ahLjCdCCgTke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "id": "lxqsxfgcg9iQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING THE APP"
      ],
      "metadata": {
        "id": "TUBWvIBxtmRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from textblob import TextBlob\n",
        "\n",
        "import pickle\n",
        "\n",
        "model=joblib.load(\"random_forest_model.pkl\")\n",
        "\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Stock Movement Prediction\", layout=\"wide\")\n",
        "\n",
        "st.title(\"Stock Price Movement Prediction\")\n",
        "st.markdown(\"\"\"\n",
        "This interactive web application predicts stock price movements based on **user-generated content** and **historical stock data**.\n",
        "It combines sentiment analysis with market trends to forecast price directions.\n",
        "\"\"\")\n",
        "\n",
        "st.sidebar.header(\"User Inputs\")\n",
        "\n",
        "stock_symbol = st.sidebar.text_input(\"Stock Symbol (e.g., AAPL, TSLA, etc.)\", value=\"AAPL\")\n",
        "\n",
        "st.sidebar.header(\"Select Date Range\")\n",
        "start_date = st.sidebar.date_input(\"Start Date\", value=pd.to_datetime(\"2020-01-01\"))\n",
        "end_date = st.sidebar.date_input(\"End Date\", value=pd.to_datetime(\"2024-01-01\"))\n",
        "\n",
        "st.sidebar.header(\"Analyze Custom Sentiment\")\n",
        "user_text = st.sidebar.text_area(\"Enter a snippet of text (e.g., a tweet or discussion):\", \"\")\n",
        "analyze_sentiment_button = st.sidebar.button(\"Analyze Sentiment\")\n",
        "\n",
        "st.sidebar.header(\"Overall Sentiment\")\n",
        "user_sentiment = st.sidebar.radio(\"Sentiment on Social Media\", (\"Positive\", \"Negative\", \"Neutral\"))\n",
        "\n",
        "if analyze_sentiment_button and user_text:\n",
        "    blob = TextBlob(user_text)\n",
        "    sentiment_polarity = blob.sentiment.polarity\n",
        "    if sentiment_polarity > 0:\n",
        "        st.sidebar.success(f\"Sentiment Analysis Result: Positive (Score: {sentiment_polarity:.2f})\")\n",
        "        sentiment_score = 1\n",
        "    elif sentiment_polarity < 0:\n",
        "        st.sidebar.error(f\"Sentiment Analysis Result: Negative (Score: {sentiment_polarity:.2f})\")\n",
        "        sentiment_score = -1\n",
        "    else:\n",
        "        st.sidebar.info(f\"Sentiment Analysis Result: Neutral (Score: {sentiment_polarity:.2f})\")\n",
        "        sentiment_score = 0\n",
        "else:\n",
        "    sentiment_score = 1 if user_sentiment == \"Positive\" else (-1 if user_sentiment == \"Negative\" else 0)\n",
        "\n",
        "st.header(f\"Stock Data for {stock_symbol}\")\n",
        "try:\n",
        "    stock_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
        "    if not stock_data.empty:\n",
        "        st.write(stock_data.tail())\n",
        "        st.line_chart(stock_data[\"Close\"], use_container_width=True)\n",
        "    else:\n",
        "        st.warning(\"No stock data found for the given date range.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error fetching data: {e}\")\n",
        "\n",
        "st.header(\"Stock Movement Prediction\")\n",
        "if st.button(\"Predict Stock Movement\"):\n",
        "    try:\n",
        "        features = np.array([[sentiment_score]])\n",
        "        prediction = model.predict(features)\n",
        "        confidence = max(model.predict_proba(features)[0])\n",
        "\n",
        "        if prediction[0] == 1:\n",
        "            st.success(f\"Prediction: The stock price is likely to go **UP**.\")\n",
        "        else:\n",
        "            st.error(f\"Prediction: The stock price is likely to go **DOWN**.\")\n",
        "\n",
        "        st.markdown(f\"**Model Confidence:** {confidence * 100:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error making prediction: {e}\")\n"
      ],
      "metadata": {
        "id": "djWd-MLp6Mpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2pGIJtOG0dHmK9SQAigPpHztPzi_28Fb1k2WQF5ujVspb4TGz\n"
      ],
      "metadata": {
        "id": "EX8VUL3khktt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  RUNNING THE APP"
      ],
      "metadata": {
        "id": "WPfeqnCkx8Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "print(f\"Access your Streamlit app here: {public_url}\")\n",
        "\n",
        "!streamlit run app.py &>/dev/null &\n"
      ],
      "metadata": {
        "id": "5boE-6RTh4Wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YyYpWjICTncX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X5NJ71a_v6BX"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}